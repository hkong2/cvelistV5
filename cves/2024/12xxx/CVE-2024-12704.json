{
    "dataType": "CVE_RECORD",
    "dataVersion": "5.1",
    "cveMetadata": {
        "cveId": "CVE-2024-12704",
        "assignerOrgId": "c09c270a-b464-47c1-9133-acb35b22c19a",
        "state": "PUBLISHED",
        "assignerShortName": "@huntr_ai",
        "dateReserved": "2024-12-17T10:58:19.646Z",
        "datePublished": "2025-03-20T10:09:06.689Z",
        "dateUpdated": "2025-03-20T10:09:06.689Z"
    },
    "containers": {
        "cna": {
            "title": "Denial of Service (DoS) in run-llama/llama_index",
            "providerMetadata": {
                "orgId": "c09c270a-b464-47c1-9133-acb35b22c19a",
                "shortName": "@huntr_ai",
                "dateUpdated": "2025-03-20T10:09:06.689Z"
            },
            "descriptions": [
                {
                    "lang": "en",
                    "value": "A vulnerability in the LangChainLLM class of the run-llama/llama_index repository, version v0.12.5, allows for a Denial of Service (DoS) attack. The stream_complete method executes the llm using a thread and retrieves the result via the get_response_gen method of the StreamingGeneratorCallbackHandler class. If the thread terminates abnormally before the _llm.predict is executed, there is no exception handling for this case, leading to an infinite loop in the get_response_gen function. This can be triggered by providing an input of an incorrect type, causing the thread to terminate and the process to continue running indefinitely."
                }
            ],
            "affected": [
                {
                    "vendor": "run-llama",
                    "product": "run-llama/llama_index",
                    "versions": [
                        {
                            "version": "unspecified",
                            "lessThan": "0.12.6",
                            "status": "affected",
                            "versionType": "custom"
                        }
                    ]
                }
            ],
            "references": [
                {
                    "url": "https://huntr.com/bounties/a0b638fd-21c6-4ba7-b381-6ab98472a02a"
                },
                {
                    "url": "https://github.com/run-llama/llama_index/commit/d1ecfb77578d089cbe66728f18f635c09aa32a05"
                }
            ],
            "metrics": [
                {
                    "cvssV3_0": {
                        "version": "3.0",
                        "attackComplexity": "LOW",
                        "attackVector": "NETWORK",
                        "availabilityImpact": "HIGH",
                        "confidentialityImpact": "NONE",
                        "integrityImpact": "NONE",
                        "privilegesRequired": "NONE",
                        "scope": "UNCHANGED",
                        "userInteraction": "NONE",
                        "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H",
                        "baseScore": 7.5,
                        "baseSeverity": "HIGH"
                    }
                }
            ],
            "problemTypes": [
                {
                    "descriptions": [
                        {
                            "type": "CWE",
                            "lang": "en",
                            "description": "CWE-755 Improper Handling of Exceptional Conditions",
                            "cweId": "CWE-755"
                        }
                    ]
                }
            ],
            "source": {
                "advisory": "a0b638fd-21c6-4ba7-b381-6ab98472a02a",
                "discovery": "EXTERNAL"
            }
        }
    }
}